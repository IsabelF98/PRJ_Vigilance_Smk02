{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description: SWC + Embeddings\n",
    "\n",
    "This notebook performs the following analysis steps:\n",
    "\n",
    "1) Load ROI representative time series (those must already exists in text file format)\n",
    "\n",
    "2) Plots static FC matrix, as well as a carpet plot\n",
    "\n",
    "3) Dimensionality Reduction from ROI to PCA components (whole time-series)\n",
    "\n",
    "4) Compute Sliding Window Correlation based on PCA representative time series\n",
    "\n",
    "5) Generate 3D Laplacian Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pickle\n",
    "import os.path as osp\n",
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from nilearn.plotting import plot_matrix\n",
    "from scipy.signal import tukey, hamming\n",
    "from sklearn.manifold  import SpectralEmbedding\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from scipy.spatial.distance import correlation as dis_corr\n",
    "from utils.base import plot_fc_matrix, compute_swc, reduce_dimensionality_pca\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "from holoviews import dim, opts\n",
    "hv.extension('bokeh')\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.RandomState(seed=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRJDIR = '/data/SFIM_Vigilance/PRJ_Vigilance_Smk02/'\n",
    "\n",
    "# NOTE: Must run ./subject_info.sh first\n",
    "# Subject and run data\n",
    "sub_runs_DF = pd.read_csv('./subject_run.txt', delimiter=' ', header=None)\n",
    "sub_runs_DF.columns = ['Sbj','Run']\n",
    "# Subject and time data\n",
    "sub_time_DF = pd.read_csv('./subject_time.txt', delimiter=' ', header=None)\n",
    "sub_time_DF.columns = ['Sbj','Time']\n",
    "\n",
    "# All subject info data frame\n",
    "sub_DF = pd.DataFrame(columns=['Sbj','Run','Time','Time Point Min','Time Point Max'])\n",
    "sub_DF['Sbj']  = sub_runs_DF['Sbj']\n",
    "sub_DF['Run']  = sub_runs_DF['Run']\n",
    "sub_DF['Time'] = sub_time_DF['Time']\n",
    "\n",
    "for i,idx in enumerate(sub_DF.index):\n",
    "    if idx == 0:\n",
    "        sub_DF.loc[idx,'Time Point Min'] = 0\n",
    "        sub_DF.loc[idx,'Time Point Max'] = sub_DF.loc[idx, 'Time'] - 1\n",
    "    else:\n",
    "        if sub_DF.loc[idx-1,'Sbj'] == sub_DF.loc[idx,'Sbj']:\n",
    "            sub_DF.loc[idx,'Time Point Min'] = sub_DF.loc[idx-1,'Time Point Max'] +1\n",
    "            sub_DF.loc[idx,'Time Point Max'] = sub_DF.loc[idx, 'Time'] -1 + sub_DF.loc[idx,'Time Point Min']\n",
    "        else:\n",
    "            sub_DF.loc[idx,'Time Point Min'] = 0\n",
    "            sub_DF.loc[idx,'Time Point Max'] = sub_DF.loc[idx, 'Time'] - 1\n",
    "\n",
    "# Dictionary of subject with valid runs\n",
    "SubDict = {}\n",
    "for i,idx in enumerate(sub_DF.index):\n",
    "    sbj  = sub_DF.loc[idx]['Sbj']\n",
    "    run  = sub_DF.loc[idx]['Run']\n",
    "    time = sub_DF.loc[idx]['Time']\n",
    "    tp_min = sub_DF.loc[idx]['Time Point Min']\n",
    "    tp_max = sub_DF.loc[idx]['Time Point Max']\n",
    "    if sbj in SubDict.keys():\n",
    "        SubDict[sbj].append((run,time,tp_min,tp_max))\n",
    "    else:\n",
    "        SubDict[sbj] = [(run,time,tp_min,tp_max)]\n",
    "SubjectList = list(SubDict.keys()) # list of subjects        \n",
    "for sbj in SubjectList:\n",
    "    SubDict[sbj].append(('All',sum(SubDict[sbj][i][1] for i in range(0,len(SubDict[sbj]))),0,sum(SubDict[sbj][i][1] for i in range(0,len(SubDict[sbj])))-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widgets for selecting subject run and window legth\n",
    "# --------------------------------------------------\n",
    "SubjSelect = pn.widgets.Select(name='Select Subject', options=SubjectList, value=SubjectList[0]) # Select subject\n",
    "RunSelect  = pn.widgets.Select(name='Select Run', options=[SubDict[SubjSelect.value][i][0] for i in range(0,len(SubDict[SubjSelect.value]))]) # Select run for chosen subject\n",
    "WindowSelect = pn.widgets.Select(name='Select Window Length', options=[30,46,60]) # Select window lenght\n",
    "\n",
    "# Updates available runs given SubjSelect value\n",
    "def update_run(event):\n",
    "    RunSelect.options = [SubDict[event.new][i][0] for i in range(0,len(SubDict[event.new]))]\n",
    "    \n",
    "SubjSelect.param.watch(update_run, 'value')\n",
    "\n",
    "pn.Row(SubjSelect, RunSelect, WindowSelect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBJ                    = SubjSelect.value\n",
    "RUN                    = RunSelect.value\n",
    "TIME                   = [SubDict[SubjSelect.value][i][1] for i in range(0,len(SubDict[SubjSelect.value])) if SubDict[SubjSelect.value][i][0] == RunSelect.value][0]\n",
    "tp_min                 = [SubDict[SubjSelect.value][i][2] for i in range(0,len(SubDict[SubjSelect.value])) if SubDict[SubjSelect.value][i][0] == RunSelect.value][0]\n",
    "tp_max                 = [SubDict[SubjSelect.value][i][3] for i in range(0,len(SubDict[SubjSelect.value])) if SubDict[SubjSelect.value][i][0] == RunSelect.value][0]\n",
    "atlas_name             = 'Craddock_T2Level_0200'\n",
    "TR                     = 2.0\n",
    "WL_sec                 = WindowSelect.value\n",
    "WS_trs                 = 1\n",
    "WL_trs                 = int(WL_sec / TR)\n",
    "dim_red_method         = 'PCA'\n",
    "dim_red_method_percent = 97.5\n",
    "le_num_dims            = 3\n",
    "le_k_NN                = 100\n",
    "\n",
    "path_ts        = osp.join(PRJDIR,'PrcsData',SBJ,'D02_Preproc_fMRI','errts.'+SBJ+'.'+atlas_name+'.wl'+str(WL_sec).zfill(3)+'s.fanaticor_ts.1D')\n",
    "path_outdir    = osp.join(PRJDIR,'PrcsData',SBJ,'D02_Preproc_fMRI')\n",
    "out_prefix     = SBJ+'_fanaticor_'+atlas_name+'_wl'+str(WL_sec).zfill(3)+'s_ws'+str(int(WS_trs*TR)).zfill(3)+'s.'+RUN\n",
    "out_pca_path   = osp.join(path_outdir,out_prefix+'_'+dim_red_method+'_vk'+str(dim_red_method_percent)+'.pca_obj.pkl')\n",
    "out_pcats_path = osp.join(path_outdir,out_prefix+'_'+dim_red_method+'_vk'+str(dim_red_method_percent)+'.pca_ts.pkl')\n",
    "out_swc_path   = osp.join(path_outdir,out_prefix+'_'+dim_red_method+'_vk'+str(dim_red_method_percent)+'.swcorr.pkl')\n",
    "out_lem_path   = osp.join(path_outdir,out_prefix+'_'+dim_red_method+'_vk'+str(dim_red_method_percent)+'.le'+str(le_num_dims)+'d_knn'+str(le_k_NN).zfill(3)+'.pkl')\n",
    "\n",
    "print('++ INFO: Selection Parameters: ')\n",
    "print(' + Subject         : %s' % SBJ)\n",
    "print(' + Run.            : %s' % RUN)\n",
    "print(' + Atlas           : %s' % atlas_name)\n",
    "print(' + SWC             : wl=%ss, ws=%ss, dim_red=%s, extra-->%s' % (str(WL_sec),str(WS_trs*TR),dim_red_method,'vk='+str(dim_red_method_percent)+'%'))\n",
    "print(' + Timeseries File : %s' % path_ts)\n",
    "print(' + -----------------------------------------------------------')\n",
    "print('++ INFO: Laplacian Embedding Settings: ')\n",
    "print(' + Number of Dimensions: %d' % le_num_dims)\n",
    "print(' + K-Nearest Neighbors : %d' % le_k_NN)\n",
    "print(' + Distance Metric: correlation distance')\n",
    "print('++ -----------------------------------------------------------')\n",
    "print(' + INFO: Outputs:')\n",
    "print(' + Output Folder       : %s' % path_outdir)\n",
    "print(' + PCA Object File     : %s' % out_pca_path)\n",
    "print(' + PCA Timeseries File : %s' % out_pcats_path)\n",
    "print(' + SWC File            : %s' % out_swc_path)\n",
    "print(' + LE  File            : %s' % out_lem_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 1. Load ROI Timeseries\n",
    "\n",
    "First, we load the time series for all representative ROIs, and show a static functional connectivity matrix and a carpet plot. This may help capture some issues with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "temp_ts_df = pd.read_csv(path_ts, sep='\\t', header=None)\n",
    "if RUN != 'All':\n",
    "    ts_df = pd.DataFrame(temp_ts_df.loc[tp_min:tp_max])\n",
    "    ts_df = ts_df.reset_index()\n",
    "    ts_df = ts_df.drop('index',axis=1)\n",
    "else:\n",
    "    ts_df = pd.DataFrame(temp_ts_df)\n",
    "Nacq,Nrois = ts_df.shape\n",
    "\n",
    "# Generate ROI names\n",
    "# ------------------\n",
    "# Those are default names, but it would be useful to have a file per atlas that contains the names\n",
    "# and we load it here.\n",
    "roi_names  = ['ROI'+str(r+1).zfill(3) for r in range(Nrois)]\n",
    "\n",
    "# Put timeseries also in Xarray form. This is necessary for plotting purposes via hvplot.Image\n",
    "# --------------------------------------------------------------------------------------------\n",
    "ts_xr      = xr.DataArray(ts_df.values,dims=['Time [TRs]','ROIs'])\n",
    "\n",
    "# Show a summary of the data being loaded.\n",
    "# ----------------------------------------\n",
    "print('++ INFO: Time-series loaded into memory [N_acq=%d, N_rois=%d]' % (Nacq, Nrois))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Generate Plot of Static Functional connectivity matrix\n",
    "# ======================================================\n",
    "fc_matrix_plot        = plot_fc_matrix(ts_df,roi_names,'single')\n",
    "\n",
    "# Generate Timeseries carpet plot\n",
    "ts_carpet_plot = ts_xr.hvplot.image(cmap='gray', width=1500, colorbar=True, title='ROI Timeseries (carpet plot) - Subject: %s' % SBJ).opts(colorbar_position='bottom')\n",
    "ts_roi_plot    = ts_df[0].hvplot(cmap='gray',width=1500,height=100)\n",
    "# Show both plots side-by-side using panel\n",
    "pn.Row(fc_matrix_plot, pn.Column(ts_carpet_plot,ts_roi_plot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 2. Dimensionality Reduction\n",
    "\n",
    "Here we reduce the dimensionality of the data via PCA. The goal is to have a smaller connectivity matrix, therefore we go from X number of ROIs to a Y number of PCA components, with Y hopefully being much smaller than X.\n",
    "\n",
    "* How many components are kept depends on the amount of variance we keep (default is 97.5%) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ts_pca_df, pca_plot, pca = reduce_dimensionality_pca(ts_df,dim_red_method_percent,sbj_id=SBJ)\n",
    "pickle.dump(pca, open(out_pca_path, \"wb\" ) )\n",
    "ts_pca_df.to_pickle(out_pcats_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 4. Create SWC Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create a tukey (or tappered window) of the appropriate length\n",
    "# =============================================================\n",
    "#window = tukey(WL_trs,.2)\n",
    "window = np.ones((WL_trs,))\n",
    "pd.DataFrame(window).hvplot(title='Sliding Window Shape',xlabel='Time [TRs]',ylabel='Amplitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Compute sliding window correlation\n",
    "# ==================================\n",
    "swc_r, swc_Z, winInfo = compute_swc(ts_pca_df,WL_trs,WS_trs,window=window)\n",
    "xr.DataArray(swc_Z.values.T,dims=['Time [Window ID]','PCA Connection']).hvplot.image(title='SWC Matrix - Fisher Z', cmap='RdBu').redim.range(value=(-1,1)).opts(width=1700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 4. Generate Laplacian Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "se             = SpectralEmbedding(n_components=le_num_dims, affinity='precomputed', n_jobs=32, random_state=seed)\n",
    "X_affinity     = kneighbors_graph(swc_Z.T,le_k_NN,include_self=True,n_jobs=32, metric=dis_corr)\n",
    "X_affinity     = 0.5 * (X_affinity + X_affinity.T)\n",
    "se_X           = se.fit_transform(X_affinity.toarray())\n",
    "print ('++ INFO: Embedding Dimensions: %s' % str(se_X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the embeddings into a dataframe (for saving and plotting)\n",
    "# =============================================================\n",
    "LE3D_df      = pd.DataFrame(columns=['x','y','z','x_norm','y_norm','z_norm','color_int','color_rgb','label'])\n",
    "LE3D_df['x'] = se_X[:,0]\n",
    "LE3D_df['y'] = se_X[:,1]\n",
    "LE3D_df['z'] = se_X[:,2]\n",
    "# Note: there is a change in scale between scikit-learn 0.19 and 0.23 when it comes to the laplacian embeddings.\n",
    "# I checked a few examples and the structure is the same, but the scale is different. To be able to represent all cases\n",
    "# on the same scale (and given that the dimensions are meaningless), I create this normalized version of the low dimensional embedding\n",
    "LE3D_df[['x_norm','y_norm','z_norm']]= LE3D_df[['x','y','z']]/LE3D_df[['x','y','z']].max()\n",
    "# External-data based color\n",
    "LE3D_df['color_int'] = [(255,255,255) for i in range(winInfo['numWins'])]\n",
    "LE3D_df['color_rgb'] = ['#ffffff' for i in range(winInfo['numWins'])]\n",
    "\n",
    "# Time-based color\n",
    "#color_int_temp = pd.DataFrame(LE3D_df['color_int'])\n",
    "#color_rgb_temp = pd.DataFrame(LE3D_df['color_rgb'])\n",
    "#color_int_temp.loc[0:411, 'color_int'] = [(244,81,30)] # color for Sleep Ascending data\n",
    "#color_rgb_temp.loc[0:411, 'color_rgb'] = ['#F4511E'] # color for Sleep Ascending data\n",
    "#color_int_temp.loc[412:823, 'color_int'] = [(255,152,0)] # color for Sleep Descending data\n",
    "#color_rgb_temp.loc[412:823, 'color_rgb'] = ['#FF9800'] # color for Sleep Descending data\n",
    "#color_int_temp.loc[824:1118, 'color_int'] = [(255,202,40)] # color for Sleep RESER data\n",
    "#color_rgb_temp.loc[824:1118, 'color_rgb'] = ['#FFCA28'] # color for Sleep RESER data\n",
    "#color_int_temp.loc[1119:1530, 'color_int'] = [(30,136,229)] # color for Wake Ascending data\n",
    "#color_rgb_temp.loc[1119:1530, 'color_rgb'] = ['#1E88E5'] # color for Wake Ascending data\n",
    "#color_int_temp.loc[1531:1942, 'color_int'] = [(41,182,246)] # color for Wake Descending data\n",
    "#color_rgb_temp.loc[1531:1942, 'color_rgb'] = ['#29B6F6'] # color for Wake Descending data\n",
    "#color_int_temp.loc[1953:2237, 'color_int'] = [(128,222,234)] # color for Wake RESER data\n",
    "#color_rgb_temp.loc[1953:2237, 'color_rgb'] = ['#80DEEA'] # color for Wake RESER data\n",
    "#LE3D_df['color_int'] = color_int_temp['color_int']\n",
    "#LE3D_df['color_rgb'] = color_rgb_temp['color_rgb']\n",
    "\n",
    "# Window Names\n",
    "LE3D_df['label'] = winInfo['winNames']\n",
    "LE3D_df.head()\n",
    "LE3D_df.to_pickle(out_lem_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('plotly')\n",
    "pn.extension('plotly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player     = pn.widgets.Player(name='Player', start=0, end=winInfo['numWins'], value=1, loop_policy='loop', width=800, step=1)\n",
    "@pn.depends(player.param.value)\n",
    "def plot_embed3d(max_win):\n",
    "    output = hv.Scatter3D((LE3D_df['x_norm'][0:max_win],\n",
    "                           LE3D_df['y_norm'][0:max_win],\n",
    "                           LE3D_df['z_norm'][0:max_win])).opts(color=LE3D_df['color_rgb'][0:max_win],\n",
    "                           size=5, \n",
    "                           xlim=(-1,1), \n",
    "                           ylim=(-1,1), \n",
    "                           zlim=(-1,1), aspect={'x':1,'y':1,'z':1}, camera_zoom=1, margins=(5,5,5,5), height=800, width=800)\n",
    "    return output\n",
    "pn.Column(player,plot_embed3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with PNAS 2015 Results (for consistency)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pre-computed results in MATLAB from one task-based subject from NI2019 \n",
    "from scipy.io import loadmat\n",
    "DATAFILE       = osp.join('/data/SFIMJGC_HCP7T/PRJ_CognitiveStateDetection02',\n",
    "                    'PrcsData_PNAS2015','SBJ06'+'/D02_CTask001/'+'SBJ06'+'_CTask001_WL'+str(30).zfill(3)+'_WS01_NROI0200_dF.mat')\n",
    "DATAMAT                              = loadmat(DATAFILE)\n",
    "pnas2015orig_ts_df                   = pd.DataFrame(DATAMAT['origTS'])\n",
    "pnas2015orig_Nacq,pnas2015orig_Nrois = pnas2015orig_ts_df.shape\n",
    "pnas2015orig_roi_names              = ['ROI'+str(r+1).zfill(3) for r in range(pnas2015orig_Nrois)]\n",
    "pnas2015orig_tr                     = DATAMAT['TR'][0][0]\n",
    "pnas2015orig_ts_xr                  = xr.DataArray(pnas2015orig_ts_df.values,dims=['Time [TRs]','ROIs'])\n",
    "print('++ Loaded this data: %s' % DATAFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Plot of Functional connectivity matrix\n",
    "pnas2015orig_fc_matrix_plot       = plot_fc_matrix(pnas2015orig_ts_df,pnas2015orig_roi_names,'single')\n",
    "# Generate Timeseries carpet plot\n",
    "pnas2015orig_ts_carpet_plot         = pnas2015orig_ts_xr.hvplot.image(cmap='gray', width=1500, colorbar=True, title='ROI Timeseries (carpet plot) - Subject: %s' % 'SBJ06').opts(colorbar_position='bottom')\n",
    "pnas2015orig_ts_roi_plot            = pnas2015orig_ts_df[0].hvplot(cmap='gray',width=1500,height=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Row(pnas2015orig_fc_matrix_plot, pnas2015orig_ts_carpet_plot)\n",
    "\n",
    "# PCA Step\n",
    "pnas2015python_ts_pca_df, pnas2015python_pca_plot, pnas2015python_pca = reduce_dimensionality_pca(pnas2015orig_ts_df,97.5,sbj_id='SBJ06', n_comp=None)\n",
    "pnas2015orig_ts_pca_df = pd.DataFrame(DATAMAT['dimRedTS'])\n",
    "print('++ INFO: PCA (as matlad did it)  --> %d components' % pnas2015orig_ts_pca_df.shape[1])\n",
    "print('++ INFO: PCA (as python does it) --> %d components' % pnas2015python_ts_pca_df.shape[1])\n",
    "pnas2015python_pca_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnas2015python_ts_pca_df['PC083'].hvplot(width=1700) * \\\n",
    "pnas2015orig_ts_pca_df[83].hvplot().opts(line_dash='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tukey (or tappered window) of the appropriate length\n",
    "# =============================================================\n",
    "pnas2015orig_wl_trs   = DATAMAT['WL'][0][0]\n",
    "pnas2015orig_ws_trs   = DATAMAT['WS'][0][0]\n",
    "pnas2015python_window = np.ones((pnas2015orig_wl_trs,))\n",
    "pnas2015orig_swc_Z    = pd.DataFrame(DATAMAT['CB']['snapshots'][0][0].T)\n",
    "pnas2015python_swc_r, pnas2015python_swc_Z, pnas2015python_winInfo = compute_swc(pnas2015python_ts_pca_df,pnas2015orig_wl_trs,pnas2015orig_ws_trs,window=pnas2015python_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.DataArray(pnas2015orig_swc_Z.values.T - pnas2015python_swc_Z.values.T,dims=['Time [Window ID]','PCA Connection']).hvplot.image(title='SWC Matrix - Fisher Z', cmap='RdBu_r').redim.range(value=(-1,1)).opts(width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nCom = 3\n",
    "k_NN = 100\n",
    "seed = np.random.RandomState(seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time     = time.time()\n",
    "X = DATAMAT['CB']['snapshots'][0][0]\n",
    "#X = pnas2015_swc_Z.T\n",
    "pnas2015_se             = SpectralEmbedding(n_components=nCom, affinity='precomputed', n_jobs=32, random_state=seed)\n",
    "pnas2015_X_affinity     = kneighbors_graph(X,k_NN,include_self=True,n_jobs=32, metric=dis_corr)\n",
    "pnas2015_X_affinity     = 0.5 * (pnas2015_X_affinity + pnas2015_X_affinity.T)\n",
    "pnas2015_se_X           = pnas2015_se.fit_transform(pnas2015_X_affinity.toarray())\n",
    "end_time                = time.time()\n",
    "print ('++ INFO: Elapset Time: '+ str(end_time - start_time))\n",
    "print ('++ INFO: Embedding Dimensions: %s' % str(pnas2015_se_X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_color_int = DATAMAT['winInfo']['color'][0][0]\n",
    "aux_color_rgb = [ '#%02x%02x%02x' % (int(aux_color_int[i,0]*255), \n",
    "                                     int(aux_color_int[i,1]*255), \n",
    "                                     int(aux_color_int[i,2]*255)) for i in np.arange(pnas2015python_winInfo['numWins'])]\n",
    "aux_win_labels = DATAMAT['winInfo']['winNames'][0][0]\n",
    "embedding_df = pd.DataFrame(columns=['x','y','z','x_norm','y_norm','z_norm','color_int','color_rgb','label'])\n",
    "embedding_df['x'] = pnas2015_se_X[:,0]\n",
    "embedding_df['y'] = pnas2015_se_X[:,1]\n",
    "embedding_df['z'] = pnas2015_se_X[:,2]\n",
    "embedding_df[['x_norm','y_norm','z_norm']]= embedding_df[['x','y','z']]/embedding_df[['x','y','z']].max()\n",
    "embedding_df['color_int'] = tuple(aux_color_int)\n",
    "embedding_df['color_rgb'] = aux_color_rgb\n",
    "embedding_df['label']     = aux_win_labels\n",
    "embedding_df.head()\n",
    "embedding_df.to_pickle('./test_embed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('plotly')\n",
    "pn.extension('plotly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nwins = embedding_df.shape[0]\n",
    "player     = pn.widgets.Player(name='Player', start=0, end=Nwins, value=1, loop_policy='loop', width=800, step=1)\n",
    "@pn.depends(player.param.value)\n",
    "def plot_embed3d(max_win):\n",
    "    output = hv.Scatter3D((embedding_df['x_norm'][0:max_win],\n",
    "                           embedding_df['y_norm'][0:max_win],\n",
    "                           embedding_df['z_norm'][0:max_win])).opts(color=embedding_df['color_rgb'][0:max_win],\n",
    "                           size=5, \n",
    "                           xlim=(-1,1), \n",
    "                           ylim=(-1,1), \n",
    "                           zlim=(-1,1), aspect={'x':1,'y':1,'z':1}, camera_zoom=1, margins=(5,5,5,5), height=800, width=800)\n",
    "    return output\n",
    "pn.Column(player,plot_embed3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:light"
  },
  "kernelspec": {
   "display_name": "Vigilance",
   "language": "python",
   "name": "vigilance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
