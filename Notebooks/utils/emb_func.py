import numpy     as np
import pandas    as pd
import xarray    as xr
import os.path as osp

def load_data(path_ts,RUN,tp_min,tp_max):
    """
    This fuction loads the data used for generating the reduced dimentional data.
    The fuction inputs the data path ("path_ts")
                       the run ("RUN")
                       and the dimensions of the run in the concatinated data "[tp_min:tp_max]"
    Depending on the run that is selected on the widgets the fuction either loads all the data (RUN=All)
    or if a single run is chosen only that runs section of the concatinated data is loaded.
    The funtion returns a pandas data frame of the data and the dimentions ("Nacq", "Nrois"),
    ROI names ("roi_names"), and X array version of the data frame ("ts_xr").
    """
    temp_ts_df = pd.read_csv(path_ts, sep='\t', header=None) # Load the concatinated data
    if RUN != 'All': # If selecting a single run
        ts_df = pd.DataFrame(temp_ts_df.loc[tp_min:tp_max]) # Load that run out of the concatinated data
        ts_df = ts_df.reset_index() # Reset index
        ts_df = ts_df.drop('index',axis=1)
    else: # If selecting all runs
        ts_df = pd.DataFrame(temp_ts_df)
    Nacq,Nrois = ts_df.shape # Save number of time points and number of ROI's
    roi_names  = ['ROI'+str(r+1).zfill(3) for r in range(Nrois)] # ROI names (should eventually be actual names)
    ts_xr      = xr.DataArray(ts_df.values,dims=['Time [TRs]','ROIs']) # Xarray frame of data
    return ts_df,Nacq,Nrois,roi_names,ts_xr

def winner_takes_all(my_array):
    """
    This function desighned to output the number that apears most frequently in a nupy array.
    This function will be used to slelect the sleep staging value of each window after sliding window correlation.
    Since the values only range from 0 to 3 any NaN values are changed to a value of 4.
    Then using the function np.bincount each value in the np array is counted.
    The value with the highest count is called the "winner".
    """
    # Changes NaN to value of 4
    if np.isnan(np.sum(my_array)) == True:
        my_array[np.isnan(my_array)] = 4
    my_array = my_array.astype(int) # Change all values in array as integers
    counts = np.bincount(my_array) # Count each element
    winner = np.argmax(counts) # Choose element with highest count
    return winner

def lapacian_dataframe(SubDict,se_X,winInfo,SBJ,RUN,TIME,WL_trs,tp_min,tp_max):
    """
    This function generates the data frame that will be used to plot the laplacian embeddings.
    An empty data frame is created with the columns for the data generated by SpectralEmbedding() function,
                                                        the normalized data,
                                                        the run each window coresponds to,
                                                        the sleep stage each window coresponds to,
                                                        the mean framewise displacement each window coresponds to,
                                                        and the window lable.
    The fuction returns a pandas data frame of the data.
    """
    PRJDIR = '/data/SFIM_Vigilance/PRJ_Vigilance_Smk02/' # Path to project directory
    LE3D_df      = pd.DataFrame(columns=['x','y','z','x_norm','y_norm','z_norm','Run','Sleep Value','Sleep Stage','Motion','label']) # Empty data frame with colunm names
    LE3D_df['x'] = se_X[:,0] # x values for each window
    LE3D_df['y'] = se_X[:,1] # y values for each window
    LE3D_df['z'] = se_X[:,2] # z values for each window
    # Note: there is a change in scale between scikit-learn 0.19 and 0.23 when it comes to the laplacian embeddings.
    # I checked a few examples and the structure is the same, but the scale is different. To be able to represent all cases
    # on the same scale (and given that the dimensions are meaningless), I create this normalized version of the low dimensional embedding
    LE3D_df[['x_norm','y_norm','z_norm']]= LE3D_df[['x','y','z']]/LE3D_df[['x','y','z']].max() # Normalized data for each window
    
    # Run based data
    # --------------
    runs_temp = pd.DataFrame(LE3D_df['Run']) # Temporary data frame to organized concatinated data by run
    if RUN == 'All':
        time_list = [SubDict[SBJ][i][1] for i in range(0,len(SubDict[SBJ])-1)] # List of TR's in each run
        run_list = [SubDict[SBJ][i][0] for i in range(0,len(SubDict[SBJ]))] # List of runs for that subject
        run_list.remove('All') # Remove "All" form list of runs
        # Depending on the window lenght, the run coresponding to the window is gereated by filling the run interval adgusted to the window lenght.
        # For example if you have a window length of 30 sec (15 TR's since TR is 2 sec) the first run would span over 0:397 TR's.
        # Any window that falls inbetween runs will labled as "Inbetween Runs".
        # This is iterated for each run in the data.
        # Note some runs have less runs then others.
        x=0
        for i in range(len(time_list)):
            runs_temp.loc[x:(x-1)+time_list[i]-(WL_trs-1), 'Run'] = [run_list[i]]
            x=x+time_list[i]-(WL_trs-1)
            if i != len(time_list)-1:
                runs_temp.loc[x:(x-1)+(WL_trs-1), 'Run'] = ['Inbetween Runs']
                x=x+(WL_trs-1)
        LE3D_df['Run'] = runs_temp['Run'] # Add column of organized runs to LE3D_df
    
    # Sleep-based data
    # ----------------
    sleep_temp = pd.DataFrame(columns=['Sleep Value','Sleep Stage']) # Temporary data frame to organized data by sleep stage
    # 1. Sleep staging data is saved as an individual data frame for each run which we will call "EEG_sleep_df".
    # If a single run is selected that data frame is simply loaded.
    # If all runs are slected then "EEG_sleep_df" is a single data frame with all runs concatinated in the same order as the concatinated data
    if RUN != 'All': # Single run
        sleep_file_path = osp.join(PRJDIR,'PrcsData',SBJ,'D02_Preproc_fMRI',SBJ+'_'+RUN+'_EEG_sleep.pkl') # Load sleep data
        EEG_sleep_df    = pd.read_pickle(sleep_file_path) # Save as pandas data frame
    else: # All runs
        run_list = [SubDict[SBJ][i][0] for i in range(0,len(SubDict[SBJ]))] # List of runs for that subject
        run_list.remove('All') # Remove "All" from list of runs
        EEG_sleep_df = pd.DataFrame(columns=['dataset','subject','cond','TR','sleep','drowsiness','spectral','seconds','stage']) # Empty sleep staged data frame with coulumn names
        # Append each runs sleep stage data to end of EEG_sleep_df
        for r in run_list:
            sleep_file_path    = osp.join(PRJDIR,'PrcsData',SBJ,'D02_Preproc_fMRI',SBJ+'_'+r+'_EEG_sleep.pkl')
            run_sleep_df = pd.read_pickle(sleep_file_path)
            EEG_sleep_df = EEG_sleep_df.append(run_sleep_df).reset_index(drop = True)
    # 2. The sleep stage value for each window is chosen using the winner_takes_all() function for that windows window length.
    for i in range(0,TIME-WL_trs+1): # Iterate through number of windows for given data (Number_of_TRs - Number_of_TRs_per_window + 1)
        sleep_array  = np.array([x for x in EEG_sleep_df.loc[i:i+(WL_trs-1), 'sleep']]) # Numpy array of values pertaining to window
        sleep_val = winner_takes_all(sleep_array) # Choose sleep value using winner_takes_all() function
        sleep_temp.loc[i, 'Sleep Value'] = int(sleep_val) # Ensure sleep value is an integer
    # 3. Asighn sleep stage to each sleep value
    #    0 = wake
    #    1 = stage 1
    #    2 = stage 2
    #    3 = stage 3
    #    4 = undetermined stage
    for i,idx in enumerate(sleep_temp.index):
        if sleep_temp.loc[idx, 'Sleep Value'] == 0:
            sleep_temp.loc[idx, 'Sleep Stage'] = 'Wake'
        elif sleep_temp.loc[idx, 'Sleep Value'] == 1:
            sleep_temp.loc[idx, 'Sleep Stage'] = 'Stage 1'
        elif sleep_temp.loc[idx, 'Sleep Value'] == 2:
            sleep_temp.loc[idx, 'Sleep Stage'] = 'Stage 2'
        elif sleep_temp.loc[idx, 'Sleep Value'] == 3:
            sleep_temp.loc[idx, 'Sleep Stage'] = 'Stage 3'
        elif sleep_temp.loc[idx, 'Sleep Value'] == 4:
            sleep_temp.loc[idx, 'Sleep Stage'] = 'Undetermined'
    # Add sleep staging data to LE3D_df
    LE3D_df['Sleep Value'] = sleep_temp['Sleep Value']
    LE3D_df['Sleep Stage'] = sleep_temp['Sleep Stage']
    
    # Motion-based data
    # -----------------
    mot_temp      = pd.DataFrame(columns=['Framewise Displacement']) # Temporary data frame to organized data by motion
    mot_file_path = osp.join(PRJDIR,'PrcsData',SBJ,'D02_Preproc_fMRI','motion_deriv.1D') # Path to derivative motion data for subject
    temp_mot_df   = pd.read_csv(mot_file_path,sep=' ',header=None,names=['trans_dx','trans_dy','trans_dz','rot_dx','rot_dy','rot_dz']) # Load derivative motion data for subject
    if RUN != 'All': # If single run slected choose motion data for that run
        mot_df = pd.DataFrame(temp_mot_df.loc[tp_min:tp_max]).reset_index(drop = True)
    else: # If all runs selected load whole motion data
        mot_df = pd.DataFrame(temp_mot_df)
    # 1. Calculate framewise displacement for each TR and save a new column in mot_df called "FD"
    mot_df['FD'] = abs(mot_df['trans_dx']) + abs(mot_df['trans_dy']) + abs(mot_df['trans_dz']) + abs(np.deg2rad(mot_df['rot_dx'])*50) + abs(np.deg2rad(mot_df['rot_dy'])*50) + abs(np.deg2rad(mot_df['rot_dz'])*50)
    # 2. The framewise displacement for each window is found by calculating the mean for that windows window length.
    for i in range(0,TIME-WL_trs+1): # Iterate through number of windows for given data (Number_of_TRs - Number_of_TRs_per_window + 1)
        mot_array = np.array([x for x in mot_df.loc[i:i+(WL_trs-1), 'FD']]) # Numpy array of values pertaining to window
        mot_mean  = np.nanmean(mot_array) # Calculate mean of array using np.nanmean() which ignores NaN values
        mot_temp.loc[i, 'Framewise Displacement'] = mot_mean # Asighn mean to window in mot_temp data frame
    LE3D_df['Motion'] = mot_temp['Framewise Displacement'] # Add motion data to LE3D_df
    
    # Add Window Names to LE3D_df
    LE3D_df['label'] = winInfo['winNames']
    return LE3D_df